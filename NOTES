Proposed ncmplr pipeline for static time analysis:
1. Expand macros; also, funcall+lambda => let if needed.
1a. Optimizations could go here -- CSE/remat, etc.
1b. Maybe delay-let that expands back into funcall+lambda, because if.
2. CPS for timed regions, as follows:
2a. For each user lambda, add an explicit continuation arg and:
2b. For each least-tail-position, funcall the continuation, except:
  No: (funcall k0 (+ (funcall foo x) (funcall bar y)))
  Yes: (funcall foo x (lambda (g0) (funcall bar y (lambda (g1) (funcall k0 (+ g0 g1))))))
  No: (funcall k0 (funcall foo x y))
  Also no: (funcall foo x y (lambda (g0) (k0 g0)))
  Yes: (funcall foo x y k0)
  (Or maybe put the continuations first.  Whatever.)
3. Actual codegen, where, for timed regions:
3a. Top-level lambda body => LDF 1f; LDC cost(B); RTN; 1: [[B]]
3b. There are no non-tail insns.  (Maybe JOIN; I think it's safe, but suboptimal.)
3c. `yield` is LDC 0; the ur-continuation is that pointing to the start.
3d. call/cc can also happen here, but do I care?
4. Runtime for (worker B):
4a. Time-translate (funcall (lambda (yield k0) B) ...) or something.  Save those two.
4b. Trampoline: LD time-left, LD time-needed, SUB, ST time-left,
      LD time-left, LDC 0, CLT, SEL for timeout,
      AP 0, ST time-needed, LD time-needed, SEL for yield; loop.
4b'. So it's 14-15 cycles per bounce, even with ST.  That's maybe kind of painful?


Dynamic timing idea:
* If you run out of time, you're unwound; no magic CPS; save state manually.
* Can waste work; can spill over.  So Don't Do That.
* At potential join point: LD time-left; LDC time-used; SUB; ST time-left
** Pessimize ifs if the delta isn't more than that.  Maybe even if it is.  Or tail-clone.
* To check: LD time-left; LDC 0; CLT; TSEL landing-pad next-insn
** Needed in loops and directly after non-tail call sites.


Remaining thoughts:
* I still like explicit "funcall".
* Could warn for non-tail funcall to suggest CPS or APS.

But wait:
* Can I use STOP for non-local return?  Will it overflow the control stack?  Or...?
* Still need to track time and watch for exhaustion; just saves unwind from recursion.


Okay, *new* new idea:
* Complete worst-case time analysis -> "loop (at most) n cycles".
* Add tagged lambda/funcall and "loop (at most) n times"; take away letrec and general lambda
** Or allow letrec but not if it's used for recursion.
** Could use magic numbers to assert tagged property upheld.
* (Compiling down to this from a Java-like HLL optional.  But could be entertaining.)
* Could do this syntactically (with lambda-tag context) or folded into compiler.
** i.e., for each block, compute the worst-case time from entering it to control stack pop,
   as they're built.  Because this is where we know exactly how many insns there are.
* Some dynamic scheduling would be nice, though....

But first:
* Maybe implement my own interpreter if/when it seems like less work than not.
* Actually implement the Lambda-Man AI idea that made the latest analysis idea seem justified.

Thoughts on the second-day twist:
* A straightforward interpreter is possible.
* The huge program size would let me, say, write all 8x car/cdr chains and use closures to them.
* (Or other ridiculous things along those lines.)
* But it's not actually useful until/unless it would actually help to predict the ghosts.
* HOWEVER.  Adding computationally difficult chaff to my ghost program may be called for.
** Bang on memory like a crazed weasel, register indirect.  That'll add up over time.
** Also, bitwise ops.  Lambda-Man doesn't have them.
** So... RC4 with the triple-xor idiom for swaps?
*** Yeah, someone could idiom-recognize it... but I bet they won't.
** Doing the occasional computed goto (that doesn't actually matter) would be a nice touch.
* Note that running out of cycles is equivalent to HALT, unlike for LMan.

More ABI wonkery:
* There's no reason you can't pass return values on the env-stack.  It's just slower, and
  this is called "CPS".  But.  This allows safely variadic continuations for effects.
** If funcall is restricted to let/funcall (or tail calls), the continuation is right there.
** Yes, it can be transformed... but I haven't written that much actual code yet.
** Related: syntactic sugar for let-nesting would be nice in general.
*** Am I really considering radical language change?
* Also, arguments can be passed on the data stack, if you know what you're doing.
** To wit, if they're going to be used in a linear/ordered way.
* More-also, it's possible to transparently save/restore the stack.
** But this might not be necessary.

Here we go again:

e ::= x | C
    | (op e)
    | (set (x*) e)
    | (if e e e)
    | (lambda (x*) t)
    | (& e*)

t ::= (ret e)
    | (goto e e)
    | (seq b t)
    | (if e t t)

b := (var (x*) e ...)
   | (rec (x*) e ...)
   | (call (x*) e e)

Expansions:
* implicit seq and &
* x => (x) for binder.
* flattenability for b, for macros.  Maybe just expand to lists?
* (seq b* t)
* (block (x*) t) => (call (x*) (lambda () t))
** But then isn't (var (x*) e) => (block (x*) (ret e))?
*** Yes and no: (var ...) is arity-checked.

(seq (var (xs) e) t)
; [[e]]; ldf [[t(newenv)]]; tap

(seq (rec (xs) e) t)
; dum; [[e]]; ldf [[t(newenv)]]; trap


(cons (x ...) t)

