Proposed ncmplr pipeline for static time analysis:
1. Expand macros; also, funcall+lambda => let if needed.
1a. Optimizations could go here -- CSE/remat, etc.
1b. Maybe delay-let that expands back into funcall+lambda, because if.
2. CPS for timed regions, as follows:
2a. For each user lambda, add an explicit continuation arg and:
2b. For each least-tail-position, funcall the continuation, except:
  No: (funcall k0 (+ (funcall foo x) (funcall bar y)))
  Yes: (funcall foo x (lambda (g0) (funcall bar y (lambda (g1) (funcall k0 (+ g0 g1))))))
  No: (funcall k0 (funcall foo x y))
  Also no: (funcall foo x y (lambda (g0) (k0 g0)))
  Yes: (funcall foo x y k0)
  (Or maybe put the continuations first.  Whatever.)
3. Actual codegen, where, for timed regions:
3a. Top-level lambda body => LDF 1f; LDC cost(B); RTN; 1: [[B]]
3b. There are no non-tail insns.  (Maybe JOIN; I think it's safe, but suboptimal.)
3c. `yield` is LDC 0; the ur-continuation is that pointing to the start.
3d. call/cc can also happen here, but do I care?
4. Runtime for (worker B):
4a. Time-translate (funcall (lambda (yield k0) B) ...) or something.  Save those two.
4b. Trampoline: LD time-left, LD time-needed, SUB, ST time-left,
      LD time-left, LDC 0, CLT, SEL for timeout,
      AP 0, ST time-needed, LD time-needed, SEL for yield; loop.
4b'. So it's 14-15 cycles per bounce, even with ST.  That's maybe kind of painful?


Dynamic timing idea:
* If you run out of time, you're unwound; no magic CPS; save state manually.
* Can waste work; can spill over.  So Don't Do That.
* At potential join point: LD time-left; LDC time-used; SUB; ST time-left
** Pessimize ifs if the delta isn't more than that.  Maybe even if it is.  Or tail-clone.
* To check: LD time-left; LDC 0; CLT; TSEL landing-pad next-insn
** Needed in loops and directly after non-tail call sites.


Remaining thoughts:
* I still like explicit "funcall".
* Could warn for non-tail funcall to suggest CPS or APS.

But wait:
* Can I use STOP for non-local return?  Will it overflow the control stack?  Or...?
* Still need to track time and watch for exhaustion; just saves unwind from recursion.


Okay, *new* new idea:
* Complete worst-case time analysis -> "loop (at most) n cycles".
* Add tagged lambda/funcall and "loop (at most) n times"; take away letrec and general lambda
** Or allow letrec but not if it's used for recursion.
** Could use magic numbers to assert tagged property upheld.
* (Compiling down to this from a Java-like HLL optional.  But could be entertaining.)
* Could do this syntactically (with lambda-tag context) or folded into compiler.
** i.e., for each block, compute the worst-case time from entering it to control stack pop,
   as they're built.  Because this is where we know exactly how many insns there are.
* Some dynamic scheduling would be nice, though....

But first:
* Maybe implement my own interpreter if/when it seems like less work than not.
* Actually implement the Lambda-Man AI idea that made the latest analysis idea seem justified.

Thoughts on the second-day twist:
* A straightforward interpreter is possible.
* The huge program size would let me, say, write all 8x car/cdr chains and use closures to them.
* (Or other ridiculous things along those lines.)
* But it's not actually useful until/unless it would actually help to predict the ghosts.
* HOWEVER.  Adding computationally difficult chaff to my ghost program may be called for.
** Bang on memory like a crazed weasel, register indirect.  That'll add up over time.
** Also, bitwise ops.  Lambda-Man doesn't have them.
** So... RC4 with the triple-xor idiom for swaps?
*** Yeah, someone could idiom-recognize it... but I bet they won't.
** Doing the occasional computed goto (that doesn't actually matter) would be a nice touch.
* Note that running out of cycles is equivalent to HALT, unlike for LMan.

More ABI wonkery:
* There's no reason you can't pass return values on the env-stack.  It's just slower, and
  this is called "CPS".  But.  This allows safely variadic continuations for effects.
** If funcall is restricted to let/funcall (or tail calls), the continuation is right there.
** Yes, it can be transformed... but I haven't written that much actual code yet.
** Related: syntactic sugar for let-nesting would be nice in general.
*** Am I really considering radical language change?
* Also, arguments can be passed on the data stack, if you know what you're doing.
** To wit, if they're going to be used in a linear/ordered way.
* More-also, it's possible to transparently save/restore the stack.
** But this might not be necessary.


This has turned into almost an actual language definition; it should maybe go somewhere else:

e ::= n | C
    | (op e)
    | (set (n*) e)
    | (if e e e)
    | (lambda (x*) s)
    | (class n (x*) s)
    | (& e*)

x ::= n
    | (: n t)

t ::= n | int | lambda

s ::= (ret e)
    | (halt e)
    | (goto e e)
    | (bind b s)
    | (seq e s)
    | (if e s s)

b := (var (x*) e ...)
   | (rec (x*) e ...)
   | (call (x*) e e)

Inference seems like it ought to happen in the expander, but:
* Now we're running check multiple times, and contemplating unrolling.  No.
* Memoize with an eq-hash?
** Make your code faster with this one weird trick!  GC researchers hate him!
* And by "inference" I mean actually that makes no sense.
* But I might still want to memoize.

The type checking context, also, mutably:
* map from class names to arg/ret lb/ub
* classes lower arg-u / raise ret-l; calls raise arg-l; lower ret-u
* as a side-effect, also knows all the classes for each name


TODO, maybe, expansions:
* (block (x*) t) => (call (x*) (class ,(gensym) () t))
** But then isn't (var (x*) e) => (block (x*) (ret e))?
*** Yes and no: (var) gets better error messages for type mismatch.
* when/unless

Notes on s/b cost:
(ret e) => (cost e) 1 kmagic 1
(goto e e) => (cost e1) (cost e2) amagic 1 (cost v)
(seq e t) => (cost e) (cost t)
(bind b t) => (cost b) (cost t)
(if e t t) => (cost e) 1 (max (cost t0) (cost t1))

(var _ e ...) => (sum cost es) 1 1
(rec _ e ...) => (sum cost es) 2 1
(call xs e1 e2) => (cost e1) (cost e2) amagic 1 (cost v)

(bind (yield) t) => C (later, (cost t))


I HATE LATTICE THEORY.

1. '()
2. '(a . d)
3. _|_

1. #f
2. cls, (lam)
3. int
4. _|_
